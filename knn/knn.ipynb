{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1062998 ML assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdoWEEt-TcuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ccb8b6-e9f6-4d16-b860-7f1b4f00f20e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#get the datasets directly from UCI's website\n",
        "url_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data'\n",
        "dataframe_train = (pd.read_csv(url_train, delim_whitespace=True, header=None).replace(\"?\", np.NaN))\n",
        "url_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test'\n",
        "dataframe_test = (pd.read_csv(url_test, delim_whitespace=True, header=None).replace(\"?\", np.NaN))\n",
        "\n",
        "#drop useless data in both training and testing datasets\n",
        "dataframe_train.drop(index=[132], axis=1, inplace=True)\n",
        "dataframe_test.drop(index=[8], axis=1, inplace=True)\n",
        "#assign information to x, and answers to y in both datasets\n",
        "train_x = dataframe_train.drop(dataframe_train.columns[[2,22,23,24,25,26,27]], axis=1)\n",
        "train_y = dataframe_train[22]\n",
        "test_x = dataframe_test.drop(dataframe_test.columns[[2,22,23,24,25,26,27]], axis=1)\n",
        "test_y = dataframe_test[22]\n",
        "\n",
        "#convert answers from dataframe into numpy array \n",
        "train_y = train_y.to_numpy()\n",
        "test_y = test_y.to_numpy()\n",
        "\n",
        "#since we group \"euthanized\" with \"died\", we might as well treat \"euthanized\" as \"died\"\n",
        "for i in range(train_y.size):\n",
        "  if train_y[i] == \"3\":\n",
        "    train_y[i] = \"2\"\n",
        "for i in range(test_y.size):\n",
        "  if test_y[i] == \"3\":\n",
        "    test_y[i] = \"2\"\n",
        "\n",
        "#implement KNNImputer for missing data in the information part of both training and testing datasets, both using the same parameters\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "train_x = imputer.fit_transform(train_x)\n",
        "test_x = imputer.fit_transform(test_x)\n",
        "\n",
        "#use min-max scaler for normalization in the information part of both training and testing datasets\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.fit_transform(test_x)\n",
        "\n",
        "#use KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')\n",
        "knn.fit(train_x, train_y)\n",
        "\n",
        "#print accuracy score for test dataset\n",
        "score = accuracy_score(knn.predict(test_x), test_y)\n",
        "print(score)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7910447761194029\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}