{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1062998.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tubuThW5lhYO",
        "outputId": "a1621f76-655f-4340-ac06-d16ed9489957"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "if os.path.isfile('1062998.h5'):\n",
        "  model = load_model('1062998.h5')\n",
        "else:\n",
        "  model = Sequential(name='Fashion_MNIST')\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1), padding='same', name='Conv1'))\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', name='Conv2'))\n",
        "  model.add(MaxPooling2D(2, 2))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', name='Conv3'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='softmax', name='Softmax'))\n",
        "  model.summary()\n",
        "  model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train, epochs=10, batch_size=600, verbose=1)\n",
        "  model.save('1062998.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test:')\n",
        "print('Loss: %s\\nAccuracy: %s' % (loss, accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Fashion_MNIST\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv2D)               (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "Conv3 (Conv2D)               (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "Softmax (Dense)              (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 87,114\n",
            "Trainable params: 87,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 67s 665ms/step - loss: 4.5978 - accuracy: 0.5803\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 66s 663ms/step - loss: 0.3661 - accuracy: 0.8710\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.3042 - accuracy: 0.8900\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.2696 - accuracy: 0.9041\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 66s 663ms/step - loss: 0.2461 - accuracy: 0.9116\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.2232 - accuracy: 0.9199\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.2040 - accuracy: 0.9262\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 66s 665ms/step - loss: 0.1872 - accuracy: 0.9320\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.1725 - accuracy: 0.9382\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 67s 666ms/step - loss: 0.1648 - accuracy: 0.9396\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2931 - accuracy: 0.9041\n",
            "Test:\n",
            "Loss: 0.29306668043136597\n",
            "Accuracy: 0.9041000008583069\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}